{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a4d046-b316-44df-9237-22f0a5a972e9",
   "metadata": {},
   "source": [
    "# OSNAP data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efb3b89-3d40-4a98-afd5-cf45848ef21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cosima_cookbook as cc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import flox  # for faster groupby in xarray with dask\n",
    "from dask.distributed import Client\n",
    "from datetime import timedelta, date\n",
    "import calendar\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "logging.captureWarnings(True)\n",
    "logging.getLogger('py.warnings').setLevel(logging.ERROR)\n",
    "logging.getLogger('distributed.utils_perf').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627f3e1-69b5-4912-b979-a29b9282cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climtas.nci\n",
    "climtas.nci.GadiClient(malloc_trim_threshold='64kib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1c643-7989-48d3-a7e8-0b7391ca770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = cc.database.create_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0528b-9774-4296-898e-b8558441022c",
   "metadata": {},
   "source": [
    "## Initialise data structure and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a7fa4-16cb-4d14-848d-c51db44fad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING! FORGETS ALL LOADED DATA!\n",
    "data = OrderedDict() # init nested dict of experiments and their analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556400c1-64f5-49b2-b819-34219852aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addexpt(k, d):\n",
    "    if k in data:\n",
    "        print('skipped {}: already exists'.format(k))\n",
    "    else:\n",
    "        data[k] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2226a-d4ee-4ef4-aba0-07171cc7cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictget(d, l):\n",
    "    \"\"\"\n",
    "    Get item in nested dict using a list of keys\n",
    "\n",
    "    d: nested dict\n",
    "    l: list of keys\n",
    "    \"\"\"\n",
    "    if len(l) == 1:\n",
    "        return d[l[0]]\n",
    "    return dictget(d[l[0]], l[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f9d20-aad9-4fa8-9c43-043099f82f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictknown(d, l):\n",
    "    \"\"\"\n",
    "    Return true if list of keys is valid in nested dict\n",
    "\n",
    "    d: nested dict\n",
    "    l: list of keys\n",
    "    \"\"\"    \n",
    "    while len(l)>0 and l[0] in d:\n",
    "        d = d[l[0]]\n",
    "        l = l[1:]\n",
    "    return len(l) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05eb897-90af-43d0-b91d-e3ccbea7902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictput(d, l, item):\n",
    "    \"\"\"\n",
    "    Put item in nested dict using a list of keys\n",
    "\n",
    "    d: nested dict\n",
    "    l: list of keys\n",
    "    item: item to be put\n",
    "    \"\"\"\n",
    "    while l[0] in d and len(l)>1:  # transerse existing keys\n",
    "        d = d[l[0]]\n",
    "        l = l[1:]\n",
    "    while len(l)>1:  # add new keys as needed\n",
    "        d[l[0]] = dict()\n",
    "        d = d[l[0]]\n",
    "        l = l[1:]\n",
    "    d[l[0]] = item\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd0172-31ad-482e-b18c-6306c22ef761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience functions\n",
    "def dget(l):\n",
    "    return dictget(data, l)\n",
    "def dknown(l):\n",
    "    return dictknown(data, l)\n",
    "def dput(l, item):\n",
    "    return dictput(data, l, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb0f6f-761e-46eb-acf9-bd9634fec0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showdata():\n",
    "    \"\"\"\n",
    "    Display structure of data\n",
    "    \"\"\"\n",
    "    for k, d in data.items():\n",
    "        print(k)\n",
    "        for k2, d2 in d.items():\n",
    "            print('  ', k2)\n",
    "            try:\n",
    "                for k3, d3 in d2.items():\n",
    "                    print('    ', k3)\n",
    "                    try:\n",
    "                        for k4, d4 in d3.items():\n",
    "                            print('      ', k4)\n",
    "                            try:\n",
    "                                for k5, d5 in d4.items():\n",
    "                                    print('        ', k5)\n",
    "                                    try:\n",
    "                                        for k6, d6 in d5.items():\n",
    "                                            print('          ', k6)\n",
    "                                    except:\n",
    "                                        pass\n",
    "                            except:\n",
    "                                pass\n",
    "                    except:\n",
    "                        pass\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dad45d9-b145-4367-a91c-6f5c8cf10f5e",
   "metadata": {},
   "source": [
    "## Set experiments, regions, date ranges, variables, frequencies etc\n",
    "1deg_jra55_iaf_omip2_cycle6\n",
    "\n",
    "1deg_jra55_iaf_omip2_cycle6_jra55v150_extension\n",
    "\n",
    "025deg_jra55_iaf_omip2_cycle6\n",
    "\n",
    "025deg_jra55_iaf_omip2_cycle6_jra55v150_extension\n",
    "\n",
    "01deg_jra55v140_iaf_cycle4\n",
    "\n",
    "01deg_jra55v140_iaf_cycle4_jra55v150_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9c8b3-73d7-47db-b69b-c6e72ccf2f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "addexpt('1', {'model':'access-om2-025',\n",
    "              'expts': ['1deg_jra55_iaf_omip2_cycle6',\n",
    "                        '1deg_jra55_iaf_omip2_cycle6_jra55v150_extension'],\n",
    "              'gridpaths': ['/g/data/ik11/grids/ocean_grid_10.nc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc002271-0776-43d2-a8f2-d1b067a7d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "addexpt('025', {'model':'access-om2-025',\n",
    "                'expts': ['025deg_jra55_iaf_omip2_cycle6',\n",
    "                          '025deg_jra55_iaf_omip2_cycle6_jra55v150_extension'],\n",
    "                'gridpaths': ['/g/data/ik11/grids/ocean_grid_025.nc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3834947-6f78-4d7c-8928-c45d94429b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "addexpt('01', {'model':'access-om2-01',\n",
    "               'expts': ['01deg_jra55v140_iaf_cycle4',\n",
    "                         '01deg_jra55v140_iaf_cycle4_jra55v150_extension'],\n",
    "               'gridpaths': ['/g/data/ik11/grids/ocean_grid_01.nc', \n",
    "                             '/g/data/cj50/access-om2/raw-output/access-om2-01/01deg_jra55v140_iaf/output000/ocean/ocean-2d-area_t.nc',\n",
    "                             '/g/data/cj50/access-om2/raw-output/access-om2-01/01deg_jra55v140_iaf/output000/ocean/ocean-2d-area_u.nc']\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f763ed5-7ec4-41c1-9ef6-130671e5636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "showdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37986e2c-908b-42d8-8992-f5f30fe31597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date range\n",
    "\n",
    "tstart = pd.to_datetime('1958', format='%Y')\n",
    "# tend = pd.to_datetime('2023-01-01', format='%Y-%m-%d')\n",
    "tend = pd.to_datetime('2023', format='%Y')\n",
    "# tend = tstart + pd.DateOffset(years=30)\n",
    "timerange = slice(tstart, tend)\n",
    "firstyear = pd.to_datetime(tstart).year  # assumes tstart is 1 January!\n",
    "lastyear = pd.to_datetime(tend).year-1  # assumes tend is 1 January!\n",
    "yearrange = str(firstyear)+'-'+str(lastyear)\n",
    "print('yearrange =', yearrange, 'complete years')\n",
    "print('tstart =', tstart)\n",
    "print('tend =', tend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fadf5e-1ab1-410b-9d4c-d3ec9aaf84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = [\n",
    "            'u', 'v',\n",
    "            'pot_temp',\n",
    "            'salt',\n",
    "            'pot_rho_0', 'pot_rho_2',\n",
    "            'sea_level',\n",
    "            'net_sfc_heating', 'frazil_3d_int_z',  # heat: https://forum.access-hive.org.au/t/net-surface-heat-and-freshwater-flux-variables/993/2\n",
    "            'pme_river',  # water\n",
    "            'sfc_salt_flux_ice', 'sfc_salt_flux_restore',  # salt\n",
    "            # 'mh_flux',  # sea ice melt\n",
    "            # 'sfc_hflux_coupler',\n",
    "            # 'sfc_hflux_from_runoff',\n",
    "            # 'sfc_hflux_pme',\n",
    "            # 'net_sfc_heating', 'frazil_3d_int_z',  # Net surface heat flux into ocean is net_sfc_heating + frazil_3d_int_z: https://github.com/COSIMA/access-om2/issues/139#issuecomment-639278547\n",
    "            # 'swflx',\n",
    "            # 'lw_heat',\n",
    "            # 'sens_heat',\n",
    "            # 'evap_heat',\n",
    "            # 'fprec_melt_heat',\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585023e-11fe-4aa1-b7f6-42e546aad905",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = ['1 monthly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b0b1d-71ec-4641-ab75-2e1d3fb27ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the North Atlantic: 70W-0E, 40N-70N\n",
    "regions = OrderedDict([\n",
    "    ('NA', {'lon': slice(-70, 0), 'lat': slice(40, 70)}),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb8eba-4261-4cda-a1a0-cbb2514107ad",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761c8a9-58c2-4d1d-965a-7328854ff308",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788708e6-0c39-429e-8626-0e4b84448964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadalldata(data, regions, freqs, varnames, timerange=timerange, ncfiles=None):\n",
    "    region = 'global'\n",
    "    reduction = 'unreduced'\n",
    "\n",
    "    varnames = list(set(varnames))\n",
    "\n",
    "    if not isinstance(ncfiles, list):\n",
    "        ncfiles = [ncfiles]*len(varnames)  # use the same ncfile for all variables\n",
    "\n",
    "    for expt in data.keys():\n",
    "        print(expt)\n",
    "        for freq in freqs:\n",
    "            kkey = [expt, region, freq, reduction]\n",
    "            for varname, ncfile in zip(varnames, ncfiles):\n",
    "                if not dknown(kkey+[varname]):\n",
    "                    if ncfile is None:\n",
    "                        print('loading', varname)\n",
    "                    else:\n",
    "                        print('loading', varname, 'from', ncfile)\n",
    "                    dput(kkey+[varname],\n",
    "                            xr.concat([\n",
    "                                    cc.querying.getvar(dget([expt, 'expts'])[0], varname, session, frequency=freq, ncfile=ncfile, decode_coords=False, start_time=str(timerange.start)),\n",
    "                                    cc.querying.getvar(dget([expt, 'expts'])[1], varname, session, frequency=freq, ncfile=ncfile, decode_coords=False, end_time=str(timerange.stop)),\n",
    "                                                        ], 'time').sel(time=timerange))\n",
    "\n",
    "        freq = 'static'\n",
    "    \n",
    "        grids = [(p, xr.open_dataset(p, chunks='auto')) for p in dget([expt, 'gridpaths'])]\n",
    "        for k in ['xt_ocean', 'yt_ocean', 'geolon_t', 'geolat_t', 'area_t',\n",
    "                  'xu_ocean', 'yu_ocean', 'geolon_c', 'geolat_c', 'area_u']:\n",
    "            kkey = [expt, region, freq, k]\n",
    "            if not dknown(kkey):\n",
    "                for (p, g) in grids:\n",
    "                    try:\n",
    "                        dput(kkey, g[k])\n",
    "                        da = g[k]\n",
    "                        print(k, 'loaded from', p)\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "                try:\n",
    "                    da = da.rename({'grid_x_T': 'xt_ocean', 'grid_y_T': 'yt_ocean'}) # fix for 01deg\n",
    "                    da.coords['xt_ocean'] = dget(kkey[0:-1]+['xt_ocean']).values\n",
    "                    da.coords['yt_ocean'] = dget(kkey[0:-1]+['yt_ocean']).values\n",
    "                    dput(kkey, da)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    da = da.rename({'grid_x_C': 'xu_ocean', 'grid_y_C': 'yu_ocean'}) # fix for 01deg\n",
    "                    da.coords['xu_ocean'] = dget(kkey[0:-1]+['xu_ocean']).values\n",
    "                    da.coords['yu_ocean'] = dget(kkey[0:-1]+['yu_ocean']).values\n",
    "                    dput(kkey, da)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c417c7-cfa6-4a2e-b31c-4e445dc0fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loadalldata(data, regions, frequencies, varnames, timerange=timerange, ncfiles=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7d961-76ca-4be7-91db-296c119dcb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "showdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f9641-3458-415b-957c-35a9c2c162f0",
   "metadata": {},
   "source": [
    "### Select data for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2be94-4740-4244-819f-7257076968a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicexy(da, r):\n",
    "    try:\n",
    "        da = da.sel(xt_ocean=r['lon'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        da = da.sel(xu_ocean=r['lon'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        da = da.sel(yt_ocean=r['lat'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        da = da.sel(yu_ocean=r['lat'])\n",
    "    except:\n",
    "        pass\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17cb1a-554b-469f-b5ac-69178d118e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# select data for each region\n",
    "reduction = 'unreduced'\n",
    "for expt in data.keys():\n",
    "    for region, region_data in regions.items():\n",
    "        for varname, vardata in dget([expt, 'global', 'static']).items():\n",
    "            if not dknown([expt, region, 'static', varname]):\n",
    "                dput([expt, region, 'static', varname], slicexy(vardata, region_data))\n",
    "        for freq in frequencies:\n",
    "            kkey = [expt, region, freq, reduction]\n",
    "            for varname, vardata in dget([expt, 'global', freq, reduction]).items():\n",
    "                if not dknown(kkey+[varname]):\n",
    "                    d = slicexy(vardata, region_data)\n",
    "                    d.attrs['subset'] = 'Subset extracted by https://github.com/aekiss/OSNAP/blob/6a7d0e5/OSNAP.ipynb'\n",
    "                    dput(kkey+[varname], d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49264a4d-90e9-4932-b6cc-4839ff41250d",
   "metadata": {},
   "source": [
    "## Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2215afd-82ce-4cdd-ab1c-57eb8df4ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/g/data/v45/aek156/notebooks/github/aekiss/OSNAP/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27989459-acff-4c7e-9bf0-42a68f54e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reduction = 'unreduced'\n",
    "for expt in data.keys():\n",
    "    dpath = os.path.join(basedir, 'access-om2-'+expt)\n",
    "    os.makedirs(dpath, exist_ok=True )\n",
    "    for region, region_data in regions.items():\n",
    "        print(region)\n",
    "        if region == 'global':\n",
    "            continue\n",
    "        for varname, vardata in dget([expt, 'global', 'static']).items():\n",
    "            fn = '_'.join(['access-om2-'+expt, 'grid', varname])+'.nc'\n",
    "            fpath = os.path.join(dpath, fn)\n",
    "            if os.path.exists(fpath):\n",
    "                print('--- skipped', fn)\n",
    "            else:\n",
    "                print('saving', fn)\n",
    "                dget([expt, region, 'static', varname]).to_netcdf(fpath+'-PARTIAL')\n",
    "                os.rename(fpath+'-PARTIAL', fpath)\n",
    "        for freq in frequencies:\n",
    "            kkey = [expt, region, freq, reduction]\n",
    "            for varname, vardata in dget(kkey).items():\n",
    "                fn = '_'.join(['access-om2-'+expt, 'var', varname])+'.nc'\n",
    "                fpath = os.path.join(dpath, fn)\n",
    "                if os.path.exists(fpath):\n",
    "                    print('--- skipped', fn)\n",
    "                else:\n",
    "                    print('saving', fn)\n",
    "                    dget(kkey+[varname]).to_netcdf(fpath+'-PARTIAL')\n",
    "                    os.rename(fpath+'-PARTIAL', fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-23.10] *",
   "language": "python",
   "name": "conda-env-analysis3-23.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
